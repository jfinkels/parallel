\documentclass{article}

\usepackage{amsthm}
\usepackage[pdftitle={Parallel random access machines}, pdfauthor={Jeffrey Finkelstein}]{hyperref}

\newtheorem*{todo}{TODO}
\newtheorem*{currently}{Currently working on..}

\newcommand{\email}[1]{\href{mailto:#1}{\nolinkurl{#1}}}

\author{Jef{}frey Finkelstein}
\date{\today}
\title{Parallel random access machines}

\begin{document}

\maketitle

\section*{Parallel random access machines}
There are many variations of the basic parallel random access machine (PRAM), which includes an arbitrary number of processors sharing an arbitrary amount of random access memory.
An exclusive-read, exclusive-write PRAM (EREW PRAM) does not allow any concurrent memory accesses (so all concurrent memory accesses must be explicitly serialized in the program).
An EREW PRAM is useful because any algorithm running on such a machine experiences no contention due to concurrent memory accesses.
A concurrent-read, concurrent-write PRAM (CRCW PRAM), on the other hand, has a unit cost for any number of processors concurrently accessing any single memory location.
In this model, contention due to concurrent memory accesses is not necessarily included in the running time.

Can an EREW PRAM simulate a CRCW PRAM (with the intention of reducing or eliminating time spent queuing memory concurrent accesses in physical hardware implementations)?
Due to a refinement of a simulation originally by Vishkin \cite{vishkin83}, a CRCW PRAM algorithm running in time $t(n)$ on $p(n)$ processors can be simulated by an EREW PRAM algorithm running in time $O(t(n)\cdot\lg n)$ on $p(n)$ processors.

\section*{Queue-read, queue-write parallel random access machines}
Gibbons, Matias, and Ramachandran \cite{gmr98a} define the queue-read, queue-write PRAM (QRQW PRAM).
Whereas the EREW PRAM does not allow concurrent memory accesses and the CRCW PRAM has a unit cost for each concurrent memory access, the QRQW PRAM has a time penalty at each step directly proportional to the number of concurrent memory accesses.
This is the cost due to memory contention (or the ``queuing delay''), intended to model the cost of servicing memory access requests sequentially at the memory module of the machine.

The QRQW PRAM is ``more powerful'' than the EREW PRAM, because we may be able to collapse multiple exclusive memory accesses into a single concurrent one.
(Even so, there are some algorithms in which such a simulation does not necessarily result in a decreased running time.)
The QRQW PRAM is ``less powerful'' than the CRCW PRAM, because the CRCW PRAM does not account for the cost due to contention during memory accesses.

\cite{gmr98a} briefly provides the simple simulation of a QRQW PRAM by a CRCW PRAM, but I could not seem to find a work which provides a simulation of a QRQW PRAM by a EREW PRAM.

\begin{todo}
  Does a simulation of a QRQW PRAM on an EREW PRAM incur a multiplicative $O(\lg n)$ penalty like the simulation of a CRCW PRAM on an EREW PRAM?
\end{todo}

\cite{gmr98a} also provides some theorems about ``time separations'' among different variants of PRAMs, but they don't seem to define what that means; it has something to do with time lower bounds.

\section*{Variants of the queue-read, queue-write parallel random access machine}

In \cite{gmr98b}, the authors define single instruction, multiple data (SIMD) QRQW PRAMs, and multiple instruction, multiple data (MIMD) QRQW PRAMs.
In \cite{gmr98a}, they define QRQW asynchronous PRAMs, in which the computation at each processor proceeds asynchronously, but concurrent memory accesses to the same memory location truly form a queue which is processed serially; the head of the queue, if it is not empty, is dequeued and processed at each time step.

\section*{Queuing shared memory machines}

The queuing shared memory (QSM) machine \cite{gmr99} is a essentially a parameterized QRQW PRAM in which the parameter $g$ scales the cost (of each step in each processor) due to memory accesses.
It is considered a ``bulk-synchrony'' model because it allows each processor to operate asynchronously between barrier synchronizations.
(This is a compromise between a completely synchronous model and a completely asynchronous model.)

\section*{Bulk synchronous parallel random access machine}

The bulk syncronous parallel (BSP) \cite{valiant89} model is really a \emph{distributed} computation model, in that it has an arbitrary number of processors, each with local memory, connected via a (stateless) network with limited bandwidth.

\begin{todo}
  Get a copy of \cite{valiant89}.
\end{todo}

The bulk synchronous PRAM (BSPRAM) \cite{tiskin98} is a generalization of the BSP model which has an arbitrary number of PRAMs connected to a bandwidth-limited shared memory (in place of a bandwidth-limited network).
If we choose the PRAMs in the BSPRAM to be QRQW PRAMs, this essentially yields a generalization of a QSM machine with an extra parameter, $l$, which measures latency at shared memory.
A QSM machine is essentially a QRQW BSPRAM with $l=1$ (since the QSM machine does not penalize latency at shared memory).

\section*{Memory access complexity}

In \cite{zstc98, zhang00}, Zhang et al. suggest that as memory access becomes a bottleneck, it pays to examine computational complexity not only in terms of time, space, and number of processors, but also in terms of \emph{memory access complexity}.
Memory access complexity measures the cost due to temporal and spatial locality of memory accesses in an algorithm (as well as ``contiguous and non-contiguous accesses, short message[s] and long message[s], etc.'' \cite{zcsm07}).

\begin{todo}
  Get our hands on a copies of \cite{zstc98} and \cite{zhang00}.
  They are hard to find because one is from a conference in Asia from 1998, and one is a dissertation at a Chinese university.
  In the meantime, a brief description of memory access complexity can be found in \cite[Section~4.3]{zcsm07}.
\end{todo}

\section*{Other models of parallel computation}

There are many, many other models of parallel computing machines; see \cite{zcsm07} for details and a listing of modern parallel computation models.
In that work, all the PRAMs as well as the QSM discussed in the previous sections are considered ``first generation'' models because they use a shared memory model.
The second generation models use distributed memory and the third hierarchical memory.

It seems that most models can be simulated on most other models with small costs.

\begin{todo}
  Which of the models mentioned in \cite{zcsm07} is closest to our current hardware?
  Which will be closest to the next-generation of hardware?
\end{todo}

\section*{Lower bounds for parallel models of computation}

\cite{mr98} provides lower bounds for certain problems on the QSM and BSP models, by using a generalized shared memory (GSM) machine.
This is a generalization of both QSM and BSP.

\section*{The explicit multi-threading machine}
Vishkin, Caragea and Lee \cite{vcl06} describe complexity measures for the Explicit Multi-Threading (XMT) machine (introduced in \cite{vdbn98}).
When computing the overall complexity of an algorithm written for the XMT machine, they include the computation depth, the number of round-trips to memory, and the queuing delay.
They also include additional cost due to thead and processor management when there are more threads than processor (which could be called ``processor contention'').

\begin{currently}
  Determining how the XMT model relates to other models for parallel computing machines.
  It currently seems most similar to the QRQW BSPRAM model, though we might also add memory access complexity costs.
\end{currently}

\section*{About this work}

Copyright 2012 Jef{}frey Finkelstein.

This work is licensed under the Creative Commons Attribution-ShareAlike License 3.0.
Visit \mbox{\url{https://creativecommons.org/licenses/by-sa/3.0/}} to view a copy of this license.

The \LaTeX{} markup which generated this document is available on the World Wide Web at \mbox{\url{https://github.com/jfinkels/parallel}}.
It is also licensed under the Creative Commons Attribution-ShareAlike License.

The author can be contacted via email at \email{jeffreyf@bu.edu}.

\bibliographystyle{plain}
\bibliography{references}

\end{document}
